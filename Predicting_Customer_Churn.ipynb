{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review**\n",
    "\n",
    "Hi, my name is Dmitry and I will be reviewing your project.\n",
    "  \n",
    "You can find my comments in colored markdown cells:\n",
    "  \n",
    "<div class=\"alert alert-success\">\n",
    "  If everything is done successfully.\n",
    "</div>\n",
    "  \n",
    "<div class=\"alert alert-warning\">\n",
    "  If I have some (optional) suggestions, or questions to think about, or general comments.\n",
    "</div>\n",
    "  \n",
    "<div class=\"alert alert-danger\">\n",
    "  If a section requires some corrections. Work can't be accepted with red comments.\n",
    "</div>\n",
    "  \n",
    "Please don't remove my comments, as it will make further review iterations much harder for me.\n",
    "  \n",
    "Feel free to reply to my comments or ask questions using the following template:\n",
    "  \n",
    "<div class=\"alert alert-info\">\n",
    "  For your comments and questions.\n",
    "</div>\n",
    "  \n",
    "First of all, thank you for turning in the project! You did an excellent job! There are some improvements that could be made (there are better choices for `repeat` and `fraction` values for upsampling/downsampling), but you successfully completed all the tasks. The project is accepted. Keep up the good work on the next sprint!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Which Customers Leave Beta Bank\n",
    "\n",
    "A bank, Beta Bank, has determined that it is cheaper to focus on retaining customers than it is to pursue new customers. They want the ability to determine which customers are likely to leave soon, so that they can focus their attention on retaining them before they decide to exit. In order to provide this ability to Beta Bank, a model needs to be trained that determines if a customer will leave the company based on their individual characteristics and features. The only true requirement provided by the bank is that the F1 score needs to be equal to or greater than **0.59**. However, the highest F1 score possible is obviously desired.\n",
    "\n",
    "This task will be completed by preprocessing the data and features. Any missing data will need to be removed or replaced, and all features need to be numeric in order to train the models. Once the data is ready to be used for model training, three model types will be analzyed. Logitic Regression, Decision Tree, and Random Forest models will be utilized for this task, and they will be checked using different methods for adjsuting class imbalance. Class imbalance will be adjusted using the `class_weight` parameter, as well as upsampling and downsampling the training data.\n",
    "\n",
    "Once the best model has been determined, it will be final tested using the test dataset. If the F1 score exceeds Beta Banks minimum requested F1 score of **0.59**, the model will be accepted and delivered to Beta Bank as the final product. Beta Bank will then be able to predict which customers are looking to leave the bank, and they can counteract by focusing their attention on retaining the specified customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "In this section the necessary libraries will be imported, the data will be read into a DataFrame, and a summary of the data will be quickly explored.\n",
    "\n",
    "### Load libraries\n",
    "\n",
    "All the important libraries that are utilized throughout this report are imported in the cell block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Hide warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Below, the csv file **/datasets/Churn.csv** will be read and stored in the DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "\n",
    "Let's take a look at the data stored in the `df` DataFrame. The first 15 rows will be printed, followed by the DataFrame's general info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>15767821</td>\n",
       "      <td>Bearce</td>\n",
       "      <td>528</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>102016.72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80181.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>15737173</td>\n",
       "      <td>Andrews</td>\n",
       "      <td>497</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76390.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>15632264</td>\n",
       "      <td>Kay</td>\n",
       "      <td>476</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26260.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>15691483</td>\n",
       "      <td>Chin</td>\n",
       "      <td>549</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190857.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>15600882</td>\n",
       "      <td>Scott</td>\n",
       "      <td>635</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65951.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0           1    15634602  Hargrave          619    France  Female   42   \n",
       "1           2    15647311      Hill          608     Spain  Female   41   \n",
       "2           3    15619304      Onio          502    France  Female   42   \n",
       "3           4    15701354      Boni          699    France  Female   39   \n",
       "4           5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5           6    15574012       Chu          645     Spain    Male   44   \n",
       "6           7    15592531  Bartlett          822    France    Male   50   \n",
       "7           8    15656148    Obinna          376   Germany  Female   29   \n",
       "8           9    15792365        He          501    France    Male   44   \n",
       "9          10    15592389        H?          684    France    Male   27   \n",
       "10         11    15767821    Bearce          528    France    Male   31   \n",
       "11         12    15737173   Andrews          497     Spain    Male   24   \n",
       "12         13    15632264       Kay          476    France  Female   34   \n",
       "13         14    15691483      Chin          549    France  Female   25   \n",
       "14         15    15600882     Scott          635     Spain  Female   35   \n",
       "\n",
       "    Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0      2.0       0.00              1          1               1   \n",
       "1      1.0   83807.86              1          0               1   \n",
       "2      8.0  159660.80              3          1               0   \n",
       "3      1.0       0.00              2          0               0   \n",
       "4      2.0  125510.82              1          1               1   \n",
       "5      8.0  113755.78              2          1               0   \n",
       "6      7.0       0.00              2          1               1   \n",
       "7      4.0  115046.74              4          1               0   \n",
       "8      4.0  142051.07              2          0               1   \n",
       "9      2.0  134603.88              1          1               1   \n",
       "10     6.0  102016.72              2          0               0   \n",
       "11     3.0       0.00              2          1               0   \n",
       "12    10.0       0.00              2          1               0   \n",
       "13     5.0       0.00              2          0               0   \n",
       "14     7.0       0.00              2          1               1   \n",
       "\n",
       "    EstimatedSalary  Exited  \n",
       "0         101348.88       1  \n",
       "1         112542.58       0  \n",
       "2         113931.57       1  \n",
       "3          93826.63       0  \n",
       "4          79084.10       0  \n",
       "5         149756.71       1  \n",
       "6          10062.80       0  \n",
       "7         119346.88       1  \n",
       "8          74940.50       0  \n",
       "9          71725.73       0  \n",
       "10         80181.12       0  \n",
       "11         76390.01       0  \n",
       "12         26260.98       0  \n",
       "13        190857.79       0  \n",
       "14         65951.65       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame `df` contains **10,000** rows and **13** columns. It appears that only the `'Tenure'` columns contains missing values, of which there are **909**, meaning that just over **9%** of data in the `'Tenure'` column is missing. This is a significant amount that will be remedied by replacing the missing values with the median tenure value from the `'Tenure'` column. Aside from that, the datatypes of all the columns look to be correct. No other preprocessing will be required besides filling in the missing values. Aside from preprocessing, the data itself will need to be adjusted prior to training the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "The data was loaded and inspected!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datapreprocessing\n",
    "\n",
    "As was stated above, there are missing values in the `'Tenure'` column that need to be replaced with the median tenure value. The below code block does just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values in the 'Tenure' column of the DataFrame with the median value of the \n",
    "# tenure column.\n",
    "\n",
    "df.loc[df['Tenure'].isna(),'Tenure'] = df['Tenure'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Ok, missing values were dealt with reasonably\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a summary of the data again to ensure that there are no longer any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check to ensure that there are no missing values\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values remain in the DataFrame! We can now move onto preparing the features for training the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Preparation\n",
    "\n",
    "Before we can begin splitting the data and training the model, we need to prepare the necessary features. It is important that the data is presented in a numeric fashion so that the models can effectively be trained without any errors. This means that any features, or columns, that contain strings or non-numeric categories will need to be transformed into some numeric grouping via one of the encoding methods. \n",
    "\n",
    "From looking at the DataFrame, the `'RowNumber'`, `'CustomerId'`, and `'Surname'` columns should have zero impact on whether or not a customer leaves or not. Additionally, their size will make encoding very tasking. Therefore, let's create a new DataFrame that drops the the `'RowNumber'`, `'CustomerId'`, and `'Surname'` columns from the dataset. The new DataFrame will be named `data_curated`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curate the dataset to only have the necessary info by dropping unecessary columns\n",
    "\n",
    "data_curated = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Useless columns were dropped\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining columns are all numeric except for `'Geography'` and `'Gender'`. Fortuantely, the `'Geography'` column only contains **3** unique values, and the `'Gender'` column only contains **2** unique values. These conditions make One-Hot Encoding (OHE) a very favorable method of encoding the dataset. When using OHE, it is important to avoid the dummy trap. The model will fall into the dummy trap when too many highly correlated columns are added to the DataFrame. Since the data is abundant and highly related to one another, the model will get confused. In order to avoid this trap, we will drop the first new column from each original feature when performing One-Hot Encoding. The cell block below will execute this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform One-Hot Encoding on data_curated\n",
    "# Pass the drop_first=True parameter to avoid the dummy trap\n",
    "# Store the newly encoded dataset in 'data_ohe'\n",
    "\n",
    "data_ohe = pd.get_dummies(data_curated, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Categorical features were encoded\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having performed One-Hot Encoding, let's take a look at the new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42     2.0       0.00              1          1   \n",
       "1             608   41     1.0   83807.86              1          0   \n",
       "2             502   42     8.0  159660.80              3          1   \n",
       "3             699   39     1.0       0.00              2          0   \n",
       "4             850   43     2.0  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39     5.0       0.00              2          1   \n",
       "9996          516   35    10.0   57369.61              1          1   \n",
       "9997          709   36     7.0       0.00              1          0   \n",
       "9998          772   42     3.0   75075.31              2          1   \n",
       "9999          792   28     5.0  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0                  1        101348.88       1                  0   \n",
       "1                  1        112542.58       0                  0   \n",
       "2                  0        113931.57       1                  0   \n",
       "3                  0         93826.63       0                  0   \n",
       "4                  1         79084.10       0                  0   \n",
       "...              ...              ...     ...                ...   \n",
       "9995               0         96270.64       0                  0   \n",
       "9996               1        101699.77       0                  0   \n",
       "9997               1         42085.58       1                  0   \n",
       "9998               0         92888.52       1                  1   \n",
       "9999               0         38190.78       0                  0   \n",
       "\n",
       "      Geography_Spain  Gender_Male  \n",
       "0                   0            0  \n",
       "1                   1            0  \n",
       "2                   0            0  \n",
       "3                   0            0  \n",
       "4                   1            0  \n",
       "...               ...          ...  \n",
       "9995                0            1  \n",
       "9996                0            1  \n",
       "9997                0            0  \n",
       "9998                0            1  \n",
       "9999                0            0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the new DataFrame, 'data_ohe'\n",
    "\n",
    "data_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the last few columns of the DataFrame are dummy columns from the `'Geography'` and `'Gender'` columns. Also notice that one dummy column from each original feature has been dropped. We have successfully performed One-Hot Encoding on our data and avoided falling into the dummy trap. Now that all the data in the DataFrame is numeric, we can finally move onto working with the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the training, validation, and test datasets\n",
    "\n",
    "We want to be able to train the model, validate the model, and then perform final testing on the model. Such actions require 3 separate datasets. Since Beta Bank has only provided one dataset, it will be split up into a training dataset, a validation dataset, and a testing dataset. A popular ratio for splitting up the data is 3:1:1, where the training dataset contains 60% of the data and both the validation and testing datasets contains 20% of the data. To split the data up, we will utilize the `train_test_split` function found in the `sklearn.model_selection` library. The below cell block will split the overall dataset into 3 separate datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training, validation, and testing datasets\n",
    "# The datasets will be split up 60%, 20%, 20% for a 3:1:1 ratio\n",
    "\n",
    "# Create the target dataset by slicing the 'Exited' column\n",
    "target = data_ohe['Exited']\n",
    "\n",
    "# Create the features dataset by dropping the 'Exited column'\n",
    "features = data_ohe.drop('Exited', axis=1)\n",
    "\n",
    "# Split the features and target datasets into training datasets and other datasets\n",
    "# The test_size will be 0.4 so that the training dataset contains 60% of the data\n",
    "features_train, features_other, target_train, target_other = train_test_split(features, target, test_size=0.4, random_state=12345)\n",
    "\n",
    "# Split the 'other' datasets into validation and testing datasets\n",
    "# The test_size will be 0.5 so that both datasets contain 50% of 40% of the data, or 20% of the overall data each.\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_other, target_other, test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "The data was split into train, validation and test sets\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the Balance of Classes\n",
    "\n",
    "Now that the datasets are split up, lets take a quick look at the class balance in the target datasets. To look at the class balances, we will calculate the percent that positive and negative classes appear within the overall dataset. This will be done for the training dataset, validation dataset, and test dataset. The percentages will be displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Negative class balance: 80.067%\n",
      "Positive class balance: 19.933%\n",
      "\n",
      "VALIDATION\n",
      "Negative class balance: 79.1%\n",
      "Positive class balance: 20.9%\n",
      "\n",
      "TEST\n",
      "Negative class balance: 78.85%\n",
      "Positive class balance: 21.15%\n"
     ]
    }
   ],
   "source": [
    "# Balance of classes for training dataset\n",
    "print('TRAINING')\n",
    "print(f'Negative class balance: {round(target_train[target_train == 0].count() * 100 / len(target_train), 3)}%') \n",
    "print(f'Positive class balance: {round(target_train[target_train == 1].count() * 100 / len(target_train), 3)}%\\n') \n",
    "\n",
    "# Balance of classes for validation dataset\n",
    "print('VALIDATION')\n",
    "print(f'Negative class balance: {round(target_valid[target_valid == 0].count() * 100 / len(target_valid), 3)}%') \n",
    "print(f'Positive class balance: {round(target_valid[target_valid == 1].count() * 100 / len(target_valid), 3)}%\\n') \n",
    "\n",
    "\n",
    "# Balance of classes for test dataset\n",
    "print('TEST')\n",
    "print(f'Negative class balance: {round(target_test[target_test == 0].count() * 100 / len(target_test), 3)}%') \n",
    "print(f'Positive class balance: {round(target_test[target_test == 1].count() * 100 / len(target_test), 3)}%') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, there is significant class imbalance. The negative class accounts for almost **80%** of the data in the training, validation, and test target datasets. The positive class only account for rougly **20%**. We will need to adjust this so that our models can be better trained and produce better results. \n",
    "\n",
    "To show the effect that adjusting class balance can have, we will train a model without adjusting the class balance and then compare it to a model that is trained after having adjusting the class balance. Before we can move onto training a model, one last step is required, and that is standardization of the data. In order to ensure that the model treates each feature equally, we must standardiz the data. This is done in the cell block below with the use of the `StandardScaler` class from the `sklearn.preprocessing` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Great, you checked the balance of classes. By the way, we can use `stratify` parameter of `train_test_split` to make sure that train, validation and test sets have the same distribution of classes as the original dataset\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train.loc[:, numeric] = scaler.transform(features_train.loc[:, numeric])\n",
    "features_valid.loc[:, numeric] = scaler.transform(features_valid.loc[:, numeric])\n",
    "features_test.loc[:, numeric] = scaler.transform(features_test.loc[:, numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Scaling was applied correctly\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is standardized for the training, validation, and testing datasets, let's train some models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a model before adjusting class imbalance\n",
    "\n",
    "Let's first train a model without having adjusted the class imbalance. Then, we will compare the results with a trained model after having adjusted the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.33108\n",
      "AUC-ROC Score: 0.75875\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of a LogisticRegression model\n",
    "model = LogisticRegression(solver='liblinear', random_state=12345)\n",
    "\n",
    "# Fit the model using the training data\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# Predict the target values of the validation features\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "# Calculate and print the F1 score\n",
    "print('F1:', round(f1_score(target_valid, predicted_valid),5))\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print(f'AUC-ROC Score: {round(auc_roc, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without adjusting the class imbalance in the dataset, the logistic regression model has a F1 score of approximately **0.331**. This F1 score is okay, but not great. We are definitely not going to deliver this model to Beta Bank. The AUC-ROC score is approximately **0.76**, which, while far from perfect, is better than a random model. Let's see how the model fairs after having adjusted the class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Alright, you trained a model without applying any balancing techniques first\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a model after adjusting the class imbalance\n",
    "\n",
    "As an attempt to increas the F1 score of the logistic regression model, let's try adjusting the class imbalance of the training dataset. We want the model to know which classes occur most often, and adjust the class weight off the results. To do this, the `class_weight` parameter will be set equal to `balanced` when initializing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.48885\n",
      "AUC-ROC Score: 0.76373\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of a LogisticRegression model\n",
    "# pass the parameter class_weight='balanced'\n",
    "model = LogisticRegression(class_weight='balanced', solver='liblinear', random_state=12345)\n",
    "\n",
    "# Fit the model using the training data\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# Predict the target values of the validation features\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "# Calculate and print the F1 score\n",
    "print('F1:', round(f1_score(target_valid, predicted_valid),5))\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print(f'AUC-ROC Score: {round(auc_roc, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having adjusted the class imbalance, the F1 score of the model is approximately **0.49**! This is much better than the F1 score of approximately **0.331** as seen previously before adjusting the class imbalance! Still, this F1 score does not meet the minimum requirement of **0.59** as provided by Beta Bank. The AUC-ROC score is slightly better than the previous model. Let's move onto utilizing other methods of adjusting class imbalance and training various models to see which ones work the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Class weights were applied successfully\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting class weight with upsampling and downsampling\n",
    "\n",
    "Aside from passing the `class_weight='balanced'` parameter to the model during initialization, we can also utilize upsampling and downsampling to adjust class imbalance. Upsampling increases the frequency of positive observations in the data, and downsampling decreases the frequency of negative observations in the data. Let's start off by taking a look at upsampling and creating a function for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust class imablance with upsampling\n",
    "\n",
    "# Create a function for upsampling the training data\n",
    "\n",
    "# Initialize the funciton\n",
    "def upsample(features, target, repeat):\n",
    "    \n",
    "    # Create datasets based on class\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    # Perform upsampling\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    # Shuffle the observations\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    # Return the upsampled data\n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that a function has been created for upsampling, let's pass the features and target datasets of the training dataset to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Upsampling was correctly applied only to the train set, but the `repeat` value doesn't really make the data balanced (is there 10 times more zeros than ones?)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how upsampling effects the performance of the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.41943\n",
      "AUC-ROC Score: 0.76535\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of a LogisticRegression model\n",
    "# pass the parameter class_weight='balanced'\n",
    "model = LogisticRegression(solver='liblinear', random_state=12345)\n",
    "\n",
    "# Fit the model using the training data\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "# Predict the target values of the validation features\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "# Calculate and print the F1 score\n",
    "print('F1:', round(f1_score(target_valid, predicted_valid),5))\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print(f'AUC-ROC Score: {round(auc_roc, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After upsampling the data, the model has an F1 score of approximatley **0.42**. This is not better than the almost **.49** F1 score seen by using the `class_weight` parameter. However, it is still better than not adjusting the class imablance at all. The AUC-ROC score is also relatively equivalnet to the AUC-ROC as seen previously from the model with the `class_weight='balanced'` parameter. Let's see how the model changes by implementing downsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for downsampling the training data\n",
    "\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "\n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=12345)\n",
    "\n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that a function has been created for downsampling, let's pass the features and target datasets of the training dataset to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Downsampling was applied correctly, but there is a similar problem to upsampling: the chosen `fraction` value doesn't make the data balanced\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how downsampling effects the performance of the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.4308390022675737\n",
      "AUC-ROC Score: 0.75836\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of a LogisticRegression model\n",
    "# pass the parameter class_weight='balanced'\n",
    "model = LogisticRegression(solver='liblinear', random_state=12345)\n",
    "\n",
    "# Fit the model using the training data\n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "\n",
    "# Predict the target values of the validation features\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "# Calculate and print the F1 score\n",
    "print('F1:', f1_score(target_valid, predicted_valid))\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print(f'AUC-ROC Score: {round(auc_roc, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score of the new model is approximately **0.43**, which is better than the model using upsampled data, but not better than the model using the `class_weight` parameter. Again, the AUC-ROC score remains unchanged for the most part. It has slightly decreased as compared to the AUC-ROC scores of the previous two models. Now that we have fully explored the performance of Logistic Regression models, let's see how Decision Tree Classifier models and Random Forest Classifier models perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING OTHER TYPES OF MODELS\n",
    "\n",
    "The below cell blocks will check the performance of Decision Tree models and Random Forest models after the class imbalance of the training dataset has been adjusted. Each model's performance will be checked after adjusting the class imbalance using the `class_weight` parameter, upsampling, and downsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree with class_weight='balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: DecisionTreeClassifier(max_depth=6, random_state=12345)\n",
      "Best F1 Score: 0.5697\n",
      "AUC-ROC Score: 0.81646\n",
      "Best Depth: 6\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Model/Learning Algorithm\n",
    "\n",
    "# Initialize\n",
    "best_DT_model = None\n",
    "best_DT_f1_score = 0\n",
    "best_DT_depth = 0\n",
    "\n",
    "# Create various models with different depth values\n",
    "\n",
    "# for loop for changing depth values (range of 1-41)\n",
    "for depth in range(1,41):\n",
    "    \n",
    "    # Create a model, using the provided depth and the same random_state\n",
    "    DT_model = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    \n",
    "    # Train the model using the training dataset\n",
    "    DT_model.fit(features_train, target_train)\n",
    "    \n",
    "    # Predict the target values of the validation features using the model\n",
    "    DT_predictions_valid = DT_model.predict(features_valid) # get model predictions on validation set\n",
    "    \n",
    "    # Calculate the f1_score, if allowed\n",
    "    try:\n",
    "        f1 = f1_score(target_valid, DT_predictions_valid)\n",
    "    except:\n",
    "        break\n",
    "        \n",
    "    # Determe best fit\n",
    "    if f1 > best_DT_f1_score:\n",
    "        best_DT_model = DT_model\n",
    "        best_DT_depth = depth\n",
    "        best_DT_f1_score = f1\n",
    "\n",
    "probabilities_valid = best_DT_model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print('Best Model:', best_DT_model)\n",
    "print(f'Best F1 Score: {round(best_DT_f1_score,4)}')\n",
    "print(f'AUC-ROC Score: {round(auc_roc, 5)}')\n",
    "print('Best Depth:', best_DT_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 Score of the Decision Tree model with the `class_weight='balanced'` parameter is the best we've seen yet! The F1 score of the model is approximately **0.57**. The AUC-ROC score is also the highest we've seen yet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree using Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: DecisionTreeClassifier(max_depth=7, random_state=12345)\n",
      "Best F1 Score: 0.5252\n",
      "AUC-ROC Score: 0.8126\n",
      "Best Depth: 7\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Model/Learning Algorithm\n",
    "\n",
    "# Initialize\n",
    "best_DT_model = None\n",
    "best_DT_f1_score = 0\n",
    "best_DT_depth = 0\n",
    "\n",
    "# Create various models with different depth values\n",
    "\n",
    "# for loop for changing depth values (range of 1-41)\n",
    "for depth in range(1,41):\n",
    "    \n",
    "    # Create a model, using the provided depth and the same random_state\n",
    "    DT_model = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    \n",
    "    # Train the model using the training dataset\n",
    "    DT_model.fit(features_upsampled, target_upsampled)\n",
    "    \n",
    "    # Predict the target values of the validation features using the model\n",
    "    DT_predictions_valid = DT_model.predict(features_valid) # get model predictions on validation set\n",
    "    \n",
    "    # Calculate the f1_score, if allowed\n",
    "    try:\n",
    "        f1 = f1_score(target_valid, DT_predictions_valid)\n",
    "    except:\n",
    "        break\n",
    "    \n",
    "    # Determe best fit\n",
    "    if f1 > best_DT_f1_score:\n",
    "        best_DT_model = DT_model\n",
    "        best_DT_depth = depth\n",
    "        best_DT_f1_score = f1\n",
    "\n",
    "probabilities_valid = best_DT_model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print('Best Model:', best_DT_model)\n",
    "print(f'Best F1 Score: {round(best_DT_f1_score,4)}')\n",
    "print(f'AUC-ROC Score: {round(auc_roc, 5)}')\n",
    "print('Best Depth:', best_DT_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing upsampling on the training dataset, the Decision Tree model has a better F1 score and AUC-ROC score than the Logistic Regression models. However, the Decision Tree model that was passed the `class_weight='balanced'` parameter still has a better F1 score and AUC-ROC score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree with Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: DecisionTreeClassifier(max_depth=5, random_state=12345)\n",
      "Best F1 Score: 0.4955\n",
      "AUC-ROC Score: 0.81491\n",
      "Best Depth: 5\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "best_DT_model = None\n",
    "best_DT_f1_score = 0\n",
    "best_DT_depth = 0\n",
    "\n",
    "# Create various models with different depth values\n",
    "\n",
    "# for loop for changing depth values (range of 1-41)\n",
    "for depth in range(1,41):\n",
    "    \n",
    "    # Create a model, using the provided depth and the same random_state\n",
    "    DT_model = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    \n",
    "    # Train the model using the training dataset\n",
    "    DT_model.fit(features_downsampled, target_downsampled)\n",
    "    \n",
    "    # Predict the target values of the validation features using the model\n",
    "    DT_predictions_valid = DT_model.predict(features_valid) # get model predictions on validation set\n",
    "    \n",
    "    # Calculate the f1_score, if allowed\n",
    "    try:\n",
    "        f1 = f1_score(target_valid, DT_predictions_valid)\n",
    "    except:\n",
    "        break\n",
    "    \n",
    "    # Determe best fit\n",
    "    if f1 > best_DT_f1_score:\n",
    "        best_DT_model = DT_model\n",
    "        best_DT_depth = depth\n",
    "        best_DT_f1_score = f1\n",
    "        \n",
    "probabilities_valid = best_DT_model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print('Best Model:', best_DT_model)\n",
    "print(f'Best F1 Score: {round(best_DT_f1_score,4)}')\n",
    "print(f'AUC-ROC Score: {round(auc_roc, 5)}')\n",
    "print('Best Depth:', best_DT_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the model using downsampled training data has a higher F1 score and AUC-ROC score than the Logistic Regression models. But, the F1 score and AUC-ROC score are not higher than the Logistic Regression model that used the `class_weight='balanced'` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest with class_weight='balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: RandomForestClassifier(max_depth=14, n_estimators=9, random_state=12345)\n",
      "Best F1 Score: 0.6\n",
      "AUC-ROC Score: 0.82229\n",
      "Best Depth: 14\n",
      "Best n_estimators: 9\n"
     ]
    }
   ],
   "source": [
    "best_RF_model = None\n",
    "best_est = 0\n",
    "best_RF_depth = 0\n",
    "best_RF_f1_score = 0\n",
    "\n",
    "# Create various models with different depth and estimator values\n",
    "\n",
    "# for loop for the number of estimators\n",
    "for est in range(1,21):\n",
    "    \n",
    "    # for loop for the depth value\n",
    "    for depth in range (1, 41):\n",
    "        \n",
    "        # Create a model, using the provided depth, number of estimators, and the same random_state\n",
    "        RF_model = RandomForestClassifier(max_depth=depth, random_state=12345, n_estimators=est)\n",
    "        \n",
    "        # Train the model using the training dataset\n",
    "        RF_model.fit(features_train, target_train)\n",
    "\n",
    "        # Predict the target values of the validation features using the model\n",
    "        RF_predictions_valid = RF_model.predict(features_valid) # get model predictions on validation set\n",
    "       \n",
    "        # Calculate the f1_score, if allowed\n",
    "        #try:\n",
    "        f1 = f1_score(target_valid, RF_predictions_valid)\n",
    "        #except:\n",
    "            #break\n",
    "\n",
    "     # Determe best fit\n",
    "        if f1 > best_RF_f1_score:\n",
    "            best_RF_model = RF_model\n",
    "            best_RF_f1_score = f1\n",
    "            best_RF_depth = depth\n",
    "            best_est = est\n",
    "\n",
    "probabilities_valid = best_RF_model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print('Best Model:', best_RF_model)\n",
    "print(f'Best F1 Score: {round(best_RF_f1_score, 4)}')\n",
    "print(f'AUC-ROC Score: {round(auc_roc, 5)}')\n",
    "print('Best Depth:', best_RF_depth)\n",
    "print('Best n_estimators:', best_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score of the Random Forest model that was passed the `class_weight='balanced'` parameter is **0.6**. This F1 score is even better than the Decision Tree models. It also satisfies the minimum F1 score of **0.59** as provided by Beta Bank! In addition to the F1 score being the highest we've seen, the model's AUC-ROC score of approximately **0.82** is the highest we've seen yet, too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest with Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: RandomForestClassifier(max_depth=14, n_estimators=20, random_state=12345)\n",
      "Best F1 Score: 0.6093\n",
      "AUC-ROC Score: 0.82729\n",
      "Best Depth: 14\n",
      "Best n_estimators: 20\n"
     ]
    }
   ],
   "source": [
    "best_RF_model = None\n",
    "best_est = 0\n",
    "best_RF_depth = 0\n",
    "best_RF_f1_score = 0\n",
    "\n",
    "# Create various models with different depth and estimator values\n",
    "\n",
    "# for loop for the number of estimators\n",
    "for est in range(1,21):\n",
    "    \n",
    "    # for loop for the depth value\n",
    "    for depth in range (1, 41):\n",
    "        \n",
    "        # Create a model, using the provided depth, number of estimators, and the same random_state\n",
    "        RF_model = RandomForestClassifier(max_depth=depth, random_state=12345, n_estimators=est)\n",
    "        \n",
    "        # Train the model using the training dataset\n",
    "        RF_model.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "        # Predict the target values of the validation features using the model\n",
    "        RF_predictions_valid = RF_model.predict(features_valid) # get model predictions on validation set\n",
    "       \n",
    "        # Calculate the f1_score, if allowed\n",
    "        try:\n",
    "            f1 = f1_score(target_valid, RF_predictions_valid)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "     # Determe best fit\n",
    "        if f1 > best_RF_f1_score:\n",
    "            best_RF_model = RF_model\n",
    "            best_RF_f1_score = f1\n",
    "            best_RF_depth = depth\n",
    "            best_est = est\n",
    "\n",
    "probabilities_valid = best_RF_model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print('Best Model:', best_RF_model)\n",
    "print(f'Best F1 Score: {round(best_RF_f1_score, 4)}')\n",
    "print(f'AUC-ROC Score: {round(auc_roc, 5)}')\n",
    "print('Best Depth:', best_RF_depth)\n",
    "print('Best n_estimators:', best_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first time, upsampling has resulted in better F1 and AUC-ROC scores than passing the `class_weight='balanced'` parameter. This Random Forest Classifier model has an F1 score of approximately **0.61** and an AUC-ROC score of approximately **0.83**. Both these values are the highest we've seen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest with Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: RandomForestClassifier(max_depth=15, n_estimators=10, random_state=12345)\n",
      "Best F1 Score: 0.4781\n",
      "AUC-ROC Score: 0.79146\n",
      "Best Depth: 15\n",
      "Best n_estimators: 10\n"
     ]
    }
   ],
   "source": [
    "best_RF_model = None\n",
    "best_est = 0\n",
    "best_RF_depth = 0\n",
    "best_RF_f1_score = 0\n",
    "\n",
    "# Create various models with different depth and estimator values\n",
    "\n",
    "# for loop for the number of estimators\n",
    "for est in range(1,21):\n",
    "    \n",
    "    # for loop for the depth value\n",
    "    for depth in range (1, 41):\n",
    "        \n",
    "        # Create a model, using the provided depth, number of estimators, and the same random_state\n",
    "        RF_model = RandomForestClassifier(max_depth=depth, random_state=12345, n_estimators=est)\n",
    "        \n",
    "        # Train the model using the training dataset\n",
    "        RF_model.fit(features_downsampled, target_downsampled)\n",
    "\n",
    "        # Predict the target values of the validation features using the model\n",
    "        RF_predictions_valid = RF_model.predict(features_valid) # get model predictions on validation set\n",
    "       \n",
    "        # Calculate the f1_score, if allowed\n",
    "        try:\n",
    "            f1 = f1_score(target_valid, RF_predictions_valid)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "     # Determe best fit\n",
    "        if f1 > best_RF_f1_score:\n",
    "            best_RF_model = RF_model\n",
    "            best_RF_f1_score = f1\n",
    "            best_RF_depth = depth\n",
    "            best_est = est\n",
    "\n",
    "probabilities_valid = best_RF_model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print('Best Model:', best_RF_model)\n",
    "print(f'Best F1 Score: {round(best_RF_f1_score, 4)}')\n",
    "print(f'AUC-ROC Score: {round(auc_roc, 5)}')\n",
    "print('Best Depth:', best_RF_depth)\n",
    "print('Best n_estimators:', best_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, downsampling did not have a profound effect on the Random Forest Classifier model. The F1 score of approximately **0.48** is rather low from the highest values we've seen. It is on par with the Logistic Regression models previously trained. However, the AUC-ROC score is still relatively high. Again, the AUC-ROC score is not perfect by any means, but it's better than other models and beats a random model by a long run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Ok, very nice, you tried a couple of other models and tuned their hyperparameters using the validation set\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final testing\n",
    "\n",
    "The model with the best F1 score and AUC-ROC score was the Random Forest Classifier model trained with upsampled data, and with a max depth of 14 branches and an n_estimators value of 20. Let's train the model one more time and test its performance using the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5931\n",
      "AUC-ROC score: 0.736\n"
     ]
    }
   ],
   "source": [
    "# Perform Final Testing\n",
    "\n",
    "# Create a model, using the provided depth, number of estimators, and the same random_state\n",
    "RF_model = RandomForestClassifier(max_depth=14, random_state=12345, n_estimators=20)\n",
    "\n",
    "# Train the model using the training dataset\n",
    "RF_model.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "test_predictions = RF_model.predict(features_test)\n",
    "\n",
    "f1 = f1_score(target_test, test_predictions)\n",
    "\n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "\n",
    "print(f'F1 Score: {round(f1, 4)}')\n",
    "print(f'AUC-ROC score: {round(auc_roc, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Great, the final model was evaluated on the test set\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained Random Forest Classifier model has an F1 score of approximately **.59**! This satisfies the requirement provided by Beta Bank! The AUC-ROC is acceptable, as it still beats a random model. However, it is lower than what was seen previously with certain validation datasets.\n",
    "\n",
    "Let's real quick see how many customers are predicted to leave out of the **2,000** customers in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474\n"
     ]
    }
   ],
   "source": [
    "# Initialize total variable\n",
    "total = 0\n",
    "\n",
    "# Create a for loop for checking each prediction in the test predictions\n",
    "for prediction in test_predictions:\n",
    "    if prediction == 1:\n",
    "        total += 1\n",
    "\n",
    "# Print the total number of customers predicted to leave the bank\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**474** customers are predicted to leave the bank! That's almost **25%** of the customers! Wow! Beta Bank better start sending out some promos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Keeping in mind that the precision of our model is far from 100%, not all of those customers will actually leave :)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta Bank requested that a model be trained to predict which customers are going to leave the bank. We first began this task by preproccesing the data and features. In order to perform training for the models, the features needed to be presented in a numeric form. To transform the categorical features into numeric features, One-Hot Encoding was performed over the categorical features. The last step in preparing the data before training models was standardizing all the features so that no one feature was determined to be more important than the others.\n",
    "\n",
    "Once the data was preprocessed, we looked at the imbalance seen in the target classes. The target datasets contained a positive and negative class. For the training, validation, and testing target datasets the negative class accounted for approximately **80%** of the data. This is a signficant imbalance since positive observations only accounted for roughly **20%** of data. The performance of a Logistic Regression model was checked with no adjustment made to the class imbalance, and then the rest of the models were trained with adjustments made to the class imbalance.\n",
    "\n",
    "Logistic Regression, Decision Tree, and Random Forest models were trained to determine which model performed the best. Each model was trained three times, with each instance of on type of model using a different class imbalance adjustment method. The first model of each model type was passed the `class_weight='balanced'` parameter so that the class imbalance was adjusted. The second and third instance of each type of model were trained using upsampled and downsampled data, respectively.\n",
    "\n",
    "Overall, the Random Forest Classifier model trained with upsampled data and with a max depth of **14** and an n_estimators value of **20** proved to perform the best. The model was tested using the test dataset, and the F1 score was calculated to be approximately **0.5931**, which is higher than the **0.59** minimum score requested by Beta Bank. This model is an acceptable product for Beta Bank, and will assist them in predicting which customers will be leaving their bank soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Excellent summary!\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 55,
    "start_time": "2022-06-07T00:17:04.564Z"
   },
   {
    "duration": 410,
    "start_time": "2022-06-07T00:17:07.715Z"
   },
   {
    "duration": 77,
    "start_time": "2022-06-07T00:17:08.127Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-07T00:17:31.582Z"
   },
   {
    "duration": 26,
    "start_time": "2022-06-07T00:17:33.565Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-07T00:19:14.317Z"
   },
   {
    "duration": 1044,
    "start_time": "2022-06-09T00:02:50.726Z"
   },
   {
    "duration": 76,
    "start_time": "2022-06-09T00:02:51.772Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-09T00:02:51.849Z"
   },
   {
    "duration": 24,
    "start_time": "2022-06-09T00:02:51.871Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-09T00:02:51.897Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-09T00:02:51.916Z"
   },
   {
    "duration": 118,
    "start_time": "2022-06-09T00:02:51.924Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-09T00:11:57.004Z"
   },
   {
    "duration": 47,
    "start_time": "2022-06-09T00:11:58.020Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-09T00:11:58.352Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-09T00:11:59.664Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-09T00:12:04.617Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-09T00:12:08.396Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:12:15.223Z"
   },
   {
    "duration": 390,
    "start_time": "2022-06-09T00:12:17.349Z"
   },
   {
    "duration": 219,
    "start_time": "2022-06-09T00:12:29.546Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:12:40.141Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:12:47.485Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:13:02.220Z"
   },
   {
    "duration": 46,
    "start_time": "2022-06-09T00:13:02.573Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-09T00:13:02.932Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-09T00:13:03.477Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:13:07.513Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-09T00:13:09.439Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:13:09.984Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-09T00:13:24.985Z"
   },
   {
    "duration": 1003,
    "start_time": "2022-06-09T00:14:43.742Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-09T00:14:44.747Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-09T00:14:44.790Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-09T00:14:44.803Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-09T00:14:44.827Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-09T00:14:53.283Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:15:26.613Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-09T00:15:27.020Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:18:04.422Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-09T00:19:04.787Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-09T00:19:05.165Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-09T00:19:05.477Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-09T00:19:07.408Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-09T00:19:09.747Z"
   },
   {
    "duration": 199,
    "start_time": "2022-06-09T00:19:12.036Z"
   },
   {
    "duration": 31,
    "start_time": "2022-06-09T00:19:12.836Z"
   },
   {
    "duration": 986,
    "start_time": "2022-06-09T00:20:50.007Z"
   },
   {
    "duration": 38,
    "start_time": "2022-06-09T00:20:50.995Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-09T00:20:51.035Z"
   },
   {
    "duration": 28,
    "start_time": "2022-06-09T00:20:51.048Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:20:54.880Z"
   },
   {
    "duration": 105,
    "start_time": "2022-06-09T00:20:56.979Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-09T00:21:04.402Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:21:28.381Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-09T00:21:29.886Z"
   },
   {
    "duration": 201,
    "start_time": "2022-06-09T00:22:53.006Z"
   },
   {
    "duration": 27,
    "start_time": "2022-06-09T00:22:53.401Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-09T00:23:05.779Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-09T00:23:08.293Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-09T00:23:31.281Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-09T00:26:08.280Z"
   },
   {
    "duration": 51,
    "start_time": "2022-06-09T00:26:37.324Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-09T00:27:18.541Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-09T00:27:28.385Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:27:49.995Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:27:58.207Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-09T00:28:45.113Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-09T00:28:50.477Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-09T00:29:01.327Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-09T00:29:10.077Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-09T00:29:28.592Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:29:44.833Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:29:46.188Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-09T00:29:48.561Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-09T00:29:52.121Z"
   },
   {
    "duration": 25,
    "start_time": "2022-06-09T00:29:52.498Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-09T00:29:54.801Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:29:56.712Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-09T00:31:15.250Z"
   },
   {
    "duration": 217,
    "start_time": "2022-06-09T00:31:20.889Z"
   },
   {
    "duration": 217,
    "start_time": "2022-06-09T00:31:28.075Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-09T00:32:07.873Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:32:36.161Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-09T00:33:52.043Z"
   },
   {
    "duration": 24,
    "start_time": "2022-06-09T00:33:56.577Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:34:04.482Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-09T00:34:25.784Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:34:30.039Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-09T00:34:36.051Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-09T00:34:36.857Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-09T00:36:14.260Z"
   },
   {
    "duration": 36,
    "start_time": "2022-06-09T00:36:20.479Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-09T00:36:20.886Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-09T00:36:22.475Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:36:25.856Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:36:26.457Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:36:27.617Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-09T00:36:36.771Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-09T00:36:37.206Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:36:37.626Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:36:37.958Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-09T00:36:38.327Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-09T00:36:39.193Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:36:41.279Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:36:43.041Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-09T00:36:43.440Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-09T00:36:45.299Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-09T00:36:45.613Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-09T00:36:49.118Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:36:49.787Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:37:00.029Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-09T00:37:19.861Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-09T00:37:20.242Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:37:20.755Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:37:22.111Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-09T00:37:22.608Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-09T00:37:23.594Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-09T00:37:26.559Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:37:26.913Z"
   },
   {
    "duration": 1017,
    "start_time": "2022-06-09T00:37:39.541Z"
   },
   {
    "duration": 38,
    "start_time": "2022-06-09T00:37:40.560Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-09T00:37:41.452Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-09T00:37:43.975Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-09T00:37:45.347Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:38:17.041Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-09T00:38:26.055Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-09T00:38:27.095Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-09T00:38:31.311Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-09T00:38:32.673Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-09T00:38:35.956Z"
   },
   {
    "duration": 23,
    "start_time": "2022-06-09T00:38:36.528Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-09T00:38:40.038Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:38:41.212Z"
   },
   {
    "duration": 388,
    "start_time": "2022-06-09T00:39:16.030Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-09T00:39:31.430Z"
   },
   {
    "duration": 994,
    "start_time": "2022-06-09T00:40:10.677Z"
   },
   {
    "duration": 39,
    "start_time": "2022-06-09T00:40:11.970Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-09T00:40:12.942Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-09T00:40:16.835Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:40:17.722Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-09T00:40:25.989Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-09T00:40:26.645Z"
   },
   {
    "duration": 26,
    "start_time": "2022-06-09T00:40:31.946Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:40:53.774Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-09T00:41:23.301Z"
   },
   {
    "duration": 969,
    "start_time": "2022-06-09T00:42:21.224Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-09T00:42:22.986Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-09T00:42:23.604Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-09T00:42:26.728Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:42:27.580Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-09T00:42:30.870Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-09T00:42:31.322Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:42:53.851Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-09T00:42:55.026Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:42:57.455Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:43:01.794Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-09T00:43:05.174Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:43:06.326Z"
   },
   {
    "duration": 23,
    "start_time": "2022-06-09T00:43:06.921Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-09T00:43:07.328Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-09T00:43:07.786Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-09T00:43:10.708Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:43:11.694Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-09T00:43:12.840Z"
   },
   {
    "duration": 61,
    "start_time": "2022-06-09T00:43:13.524Z"
   },
   {
    "duration": 45,
    "start_time": "2022-06-09T00:49:06.046Z"
   },
   {
    "duration": 119,
    "start_time": "2022-06-09T00:49:07.340Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-09T00:50:21.067Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-09T00:51:37.197Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:51:38.890Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:51:49.811Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-09T00:52:14.991Z"
   },
   {
    "duration": 130,
    "start_time": "2022-06-09T00:52:15.450Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-09T00:52:15.974Z"
   },
   {
    "duration": 25,
    "start_time": "2022-06-09T00:53:14.341Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-09T00:53:15.313Z"
   },
   {
    "duration": 983,
    "start_time": "2022-06-09T00:53:46.166Z"
   },
   {
    "duration": 51,
    "start_time": "2022-06-09T00:53:47.151Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-09T00:53:47.204Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-09T00:53:47.219Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-09T00:53:47.241Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-09T00:53:47.245Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-09T00:53:47.257Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-09T00:53:47.278Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-09T00:53:47.285Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-09T00:53:47.293Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-09T00:53:47.301Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T00:53:47.316Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-09T00:53:47.321Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T00:53:47.353Z"
   },
   {
    "duration": 33,
    "start_time": "2022-06-09T00:53:47.365Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-09T00:53:47.399Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-09T00:53:47.413Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-09T00:53:47.432Z"
   },
   {
    "duration": 113,
    "start_time": "2022-06-09T00:53:47.456Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-09T00:53:47.570Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-09T00:53:47.572Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-09T00:53:56.346Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-09T00:53:57.370Z"
   },
   {
    "duration": 27,
    "start_time": "2022-06-09T00:53:58.414Z"
   },
   {
    "duration": 1021,
    "start_time": "2022-06-09T21:52:54.866Z"
   },
   {
    "duration": 83,
    "start_time": "2022-06-09T21:53:54.428Z"
   },
   {
    "duration": 30,
    "start_time": "2022-06-09T21:54:20.700Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-09T21:54:22.995Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-09T22:00:37.116Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T22:07:15.844Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T22:07:39.572Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-09T22:14:18.611Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-09T22:14:58.319Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-09T22:14:59.079Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-09T22:26:47.402Z"
   },
   {
    "duration": 109,
    "start_time": "2022-06-09T22:29:17.930Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-09T22:29:21.382Z"
   },
   {
    "duration": 1089,
    "start_time": "2022-06-09T22:29:50.296Z"
   },
   {
    "duration": 44,
    "start_time": "2022-06-09T22:29:51.387Z"
   },
   {
    "duration": 32,
    "start_time": "2022-06-09T22:29:51.433Z"
   },
   {
    "duration": 30,
    "start_time": "2022-06-09T22:29:51.468Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-09T22:29:51.501Z"
   },
   {
    "duration": 27,
    "start_time": "2022-06-09T22:29:51.518Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-09T22:29:51.547Z"
   },
   {
    "duration": 35,
    "start_time": "2022-06-09T22:29:51.569Z"
   },
   {
    "duration": 29,
    "start_time": "2022-06-09T22:29:51.605Z"
   },
   {
    "duration": 37,
    "start_time": "2022-06-09T22:29:51.636Z"
   },
   {
    "duration": 58,
    "start_time": "2022-06-09T22:29:51.675Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-09T22:29:51.735Z"
   },
   {
    "duration": 114,
    "start_time": "2022-06-09T22:29:51.740Z"
   },
   {
    "duration": 72,
    "start_time": "2022-06-09T22:29:51.857Z"
   },
   {
    "duration": 100,
    "start_time": "2022-06-09T22:29:51.931Z"
   },
   {
    "duration": 1035,
    "start_time": "2022-06-09T22:37:00.970Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-09T22:37:02.008Z"
   },
   {
    "duration": 24,
    "start_time": "2022-06-09T22:37:02.052Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-09T22:37:02.078Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T22:37:02.092Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-09T22:37:02.099Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-09T22:37:02.112Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-09T22:37:02.133Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-09T22:37:02.149Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-09T22:37:02.171Z"
   },
   {
    "duration": 52,
    "start_time": "2022-06-09T22:37:02.182Z"
   },
   {
    "duration": 272,
    "start_time": "2022-06-09T22:37:02.236Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-09T22:37:02.509Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-09T22:37:02.511Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-09T22:37:02.512Z"
   },
   {
    "duration": 38,
    "start_time": "2022-06-09T22:37:31.960Z"
   },
   {
    "duration": 25,
    "start_time": "2022-06-09T22:45:05.775Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-09T22:52:34.563Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-09T22:52:42.048Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-09T22:52:58.494Z"
   },
   {
    "duration": 996,
    "start_time": "2022-06-09T22:53:27.877Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-09T22:53:28.875Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-09T22:53:28.918Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-09T22:53:28.939Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T22:53:28.962Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-09T22:53:28.967Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T22:53:28.982Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-09T22:53:28.987Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-09T22:53:29.009Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-09T22:53:29.032Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-09T22:53:29.042Z"
   },
   {
    "duration": 74,
    "start_time": "2022-06-09T22:53:29.056Z"
   },
   {
    "duration": 101,
    "start_time": "2022-06-09T22:53:29.132Z"
   },
   {
    "duration": 93,
    "start_time": "2022-06-09T22:53:29.235Z"
   },
   {
    "duration": 127,
    "start_time": "2022-06-09T22:53:29.330Z"
   },
   {
    "duration": 178,
    "start_time": "2022-06-09T22:53:29.459Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-09T22:53:29.639Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-09T22:53:29.643Z"
   },
   {
    "duration": 239,
    "start_time": "2022-06-09T22:53:46.367Z"
   },
   {
    "duration": 1050,
    "start_time": "2022-06-09T22:53:54.514Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-09T22:53:55.566Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-09T22:53:55.609Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-09T22:53:55.632Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T22:53:55.648Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-09T22:53:55.654Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T22:53:55.667Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-09T22:53:55.673Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-09T22:53:55.686Z"
   },
   {
    "duration": 27,
    "start_time": "2022-06-09T22:53:55.704Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-09T22:53:55.732Z"
   },
   {
    "duration": 86,
    "start_time": "2022-06-09T22:53:55.744Z"
   },
   {
    "duration": 98,
    "start_time": "2022-06-09T22:53:55.832Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-09T22:53:55.932Z"
   },
   {
    "duration": 183,
    "start_time": "2022-06-09T22:53:55.949Z"
   },
   {
    "duration": 137,
    "start_time": "2022-06-09T22:53:56.134Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-09T22:53:56.273Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-09T22:53:56.281Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T22:58:34.283Z"
   },
   {
    "duration": 116,
    "start_time": "2022-06-09T22:58:35.083Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-09T22:59:02.206Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-09T22:59:17.163Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T22:59:25.112Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-09T22:59:29.306Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-09T22:59:34.810Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-09T22:59:39.583Z"
   },
   {
    "duration": 80,
    "start_time": "2022-06-09T22:59:41.450Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-09T23:02:20.898Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T23:02:23.850Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-09T23:02:24.189Z"
   },
   {
    "duration": 58,
    "start_time": "2022-06-09T23:02:24.519Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T23:02:26.124Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-09T23:02:26.471Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-09T23:02:28.308Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T23:03:37.039Z"
   },
   {
    "duration": 37,
    "start_time": "2022-06-09T23:09:05.493Z"
   },
   {
    "duration": 57,
    "start_time": "2022-06-09T23:09:19.273Z"
   },
   {
    "duration": 68,
    "start_time": "2022-06-09T23:09:31.763Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-09T23:09:50.232Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T23:09:58.491Z"
   },
   {
    "duration": 30,
    "start_time": "2022-06-09T23:10:02.898Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T23:10:04.155Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-09T23:13:19.292Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-09T23:15:09.240Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-09T23:15:42.353Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-09T23:15:46.592Z"
   },
   {
    "duration": 538,
    "start_time": "2022-06-09T23:15:53.738Z"
   },
   {
    "duration": 520,
    "start_time": "2022-06-09T23:16:11.433Z"
   },
   {
    "duration": 500,
    "start_time": "2022-06-09T23:17:29.664Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-09T23:20:51.423Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T23:21:02.814Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-09T23:21:06.623Z"
   },
   {
    "duration": 28,
    "start_time": "2022-06-09T23:21:32.815Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T23:21:33.558Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-09T23:21:34.636Z"
   },
   {
    "duration": 30,
    "start_time": "2022-06-09T23:25:36.617Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-09T23:25:41.722Z"
   },
   {
    "duration": 1081,
    "start_time": "2022-06-09T23:26:06.419Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-09T23:26:07.503Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-09T23:26:07.546Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-09T23:26:07.570Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T23:26:07.587Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-09T23:26:07.592Z"
   },
   {
    "duration": 25,
    "start_time": "2022-06-09T23:26:07.605Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-09T23:26:07.632Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-09T23:26:07.648Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-09T23:26:07.667Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-09T23:26:07.684Z"
   },
   {
    "duration": 37,
    "start_time": "2022-06-09T23:26:07.696Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T23:26:07.735Z"
   },
   {
    "duration": 114,
    "start_time": "2022-06-09T23:26:07.829Z"
   },
   {
    "duration": 85,
    "start_time": "2022-06-09T23:26:07.945Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T23:26:08.032Z"
   },
   {
    "duration": 98,
    "start_time": "2022-06-09T23:26:08.038Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-09T23:26:08.138Z"
   },
   {
    "duration": 106,
    "start_time": "2022-06-09T23:26:08.229Z"
   },
   {
    "duration": 206,
    "start_time": "2022-06-09T23:26:08.337Z"
   },
   {
    "duration": 83,
    "start_time": "2022-06-09T23:26:08.546Z"
   },
   {
    "duration": 106,
    "start_time": "2022-06-09T23:26:08.631Z"
   },
   {
    "duration": 84,
    "start_time": "2022-06-09T23:43:07.146Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-09T23:43:12.281Z"
   },
   {
    "duration": 98,
    "start_time": "2022-06-09T23:44:57.853Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-09T23:45:09.034Z"
   },
   {
    "duration": 5221,
    "start_time": "2022-06-09T23:45:15.607Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-09T23:47:35.059Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-09T23:47:48.360Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-09T23:48:47.747Z"
   },
   {
    "duration": 9001,
    "start_time": "2022-06-09T23:49:05.027Z"
   },
   {
    "duration": 951,
    "start_time": "2022-06-09T23:52:24.721Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-09T23:52:25.673Z"
   },
   {
    "duration": 24,
    "start_time": "2022-06-09T23:52:25.716Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-09T23:52:25.741Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T23:52:25.753Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-09T23:52:25.759Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-09T23:52:25.776Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-09T23:52:25.781Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-09T23:52:25.798Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-09T23:52:25.827Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-09T23:52:25.837Z"
   },
   {
    "duration": 81,
    "start_time": "2022-06-09T23:52:25.848Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-09T23:52:48.681Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-09T23:53:40.859Z"
   },
   {
    "duration": 29,
    "start_time": "2022-06-09T23:54:43.591Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-09T23:54:58.845Z"
   },
   {
    "duration": 30,
    "start_time": "2022-06-09T23:55:07.456Z"
   },
   {
    "duration": 96,
    "start_time": "2022-06-09T23:57:39.288Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-09T23:57:44.544Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-09T23:58:03.087Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-09T23:58:13.607Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-09T23:58:20.187Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-09T23:59:44.137Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-09T23:59:53.487Z"
   },
   {
    "duration": 1005,
    "start_time": "2022-06-10T00:00:07.078Z"
   },
   {
    "duration": 43,
    "start_time": "2022-06-10T00:00:08.085Z"
   },
   {
    "duration": 24,
    "start_time": "2022-06-10T00:00:08.129Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T00:00:08.155Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-10T00:00:08.170Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T00:00:08.179Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-10T00:00:08.194Z"
   },
   {
    "duration": 35,
    "start_time": "2022-06-10T00:00:08.199Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-10T00:00:08.236Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T00:00:08.260Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-10T00:00:08.270Z"
   },
   {
    "duration": 48,
    "start_time": "2022-06-10T00:00:08.282Z"
   },
   {
    "duration": 107,
    "start_time": "2022-06-10T00:00:08.332Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-10T00:00:08.526Z"
   },
   {
    "duration": 114,
    "start_time": "2022-06-10T00:00:08.536Z"
   },
   {
    "duration": 78,
    "start_time": "2022-06-10T00:00:08.652Z"
   },
   {
    "duration": 5596,
    "start_time": "2022-06-10T00:00:08.732Z"
   },
   {
    "duration": 96,
    "start_time": "2022-06-10T00:00:14.332Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T00:00:14.430Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T00:00:14.444Z"
   },
   {
    "duration": 10242,
    "start_time": "2022-06-10T00:00:14.530Z"
   },
   {
    "duration": 118,
    "start_time": "2022-06-10T00:00:24.831Z"
   },
   {
    "duration": 82,
    "start_time": "2022-06-10T00:00:24.952Z"
   },
   {
    "duration": 97,
    "start_time": "2022-06-10T00:00:25.036Z"
   },
   {
    "duration": 94,
    "start_time": "2022-06-10T00:00:25.134Z"
   },
   {
    "duration": 66,
    "start_time": "2022-06-10T00:00:25.230Z"
   },
   {
    "duration": 658,
    "start_time": "2022-06-10T00:00:25.298Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T00:01:04.732Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T00:01:20.678Z"
   },
   {
    "duration": 511,
    "start_time": "2022-06-10T00:03:38.720Z"
   },
   {
    "duration": 1019,
    "start_time": "2022-06-10T00:05:10.681Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-10T00:05:11.702Z"
   },
   {
    "duration": 24,
    "start_time": "2022-06-10T00:05:11.746Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T00:05:11.771Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T00:05:11.786Z"
   },
   {
    "duration": 27,
    "start_time": "2022-06-10T00:05:11.792Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T00:05:11.828Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T00:05:11.834Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-10T00:05:11.851Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T00:05:11.872Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T00:05:11.886Z"
   },
   {
    "duration": 36,
    "start_time": "2022-06-10T00:05:11.898Z"
   },
   {
    "duration": 103,
    "start_time": "2022-06-10T00:05:12.026Z"
   },
   {
    "duration": 94,
    "start_time": "2022-06-10T00:05:12.133Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T00:05:12.229Z"
   },
   {
    "duration": 83,
    "start_time": "2022-06-10T00:05:12.246Z"
   },
   {
    "duration": 5859,
    "start_time": "2022-06-10T00:05:12.331Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-10T00:05:18.229Z"
   },
   {
    "duration": 104,
    "start_time": "2022-06-10T00:05:18.238Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T00:05:18.344Z"
   },
   {
    "duration": 9401,
    "start_time": "2022-06-10T00:05:18.427Z"
   },
   {
    "duration": 265,
    "start_time": "2022-06-10T00:05:27.832Z"
   },
   {
    "duration": 527,
    "start_time": "2022-06-10T00:05:28.099Z"
   },
   {
    "duration": 29,
    "start_time": "2022-06-10T00:05:28.627Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T00:05:28.727Z"
   },
   {
    "duration": 374,
    "start_time": "2022-06-10T00:05:28.735Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T00:05:51.731Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-10T00:06:02.124Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T00:07:15.680Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-10T00:07:41.183Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T00:08:15.893Z"
   },
   {
    "duration": 498,
    "start_time": "2022-06-10T00:09:47.596Z"
   },
   {
    "duration": 893,
    "start_time": "2022-06-10T00:10:00.013Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T00:10:05.585Z"
   },
   {
    "duration": 29,
    "start_time": "2022-06-10T00:10:07.611Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-10T00:10:08.115Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T00:10:12.625Z"
   },
   {
    "duration": 129,
    "start_time": "2022-06-10T00:11:09.608Z"
   },
   {
    "duration": 78,
    "start_time": "2022-06-10T00:11:18.948Z"
   },
   {
    "duration": 78,
    "start_time": "2022-06-10T00:11:30.351Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-10T00:12:48.377Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-10T00:12:56.316Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T00:14:38.554Z"
   },
   {
    "duration": 1024,
    "start_time": "2022-06-10T00:17:30.762Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-10T00:17:33.450Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T00:17:34.142Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T00:17:57.025Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-10T00:18:08.311Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T00:18:10.134Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T00:18:13.845Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T00:18:16.707Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-10T00:18:17.506Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T00:19:07.831Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T00:19:15.580Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T00:19:22.544Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T00:19:30.377Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-10T00:25:23.769Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T00:25:40.762Z"
   },
   {
    "duration": 111,
    "start_time": "2022-06-10T00:25:49.165Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T00:26:26.933Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T00:27:40.316Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T00:27:47.552Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-10T00:27:50.941Z"
   },
   {
    "duration": 61,
    "start_time": "2022-06-10T00:27:51.424Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-10T00:27:58.477Z"
   },
   {
    "duration": 157,
    "start_time": "2022-06-10T00:27:58.871Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T00:28:03.275Z"
   },
   {
    "duration": 31,
    "start_time": "2022-06-10T00:28:03.672Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-10T00:28:10.209Z"
   },
   {
    "duration": 35,
    "start_time": "2022-06-10T00:28:10.584Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T00:28:14.146Z"
   },
   {
    "duration": 57,
    "start_time": "2022-06-10T00:28:14.455Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T00:28:17.519Z"
   },
   {
    "duration": 58,
    "start_time": "2022-06-10T00:28:17.874Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T00:28:20.922Z"
   },
   {
    "duration": 179,
    "start_time": "2022-06-10T00:28:21.247Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T00:28:23.853Z"
   },
   {
    "duration": 81,
    "start_time": "2022-06-10T00:28:24.159Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T00:28:27.075Z"
   },
   {
    "duration": 133,
    "start_time": "2022-06-10T00:28:27.397Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T00:28:37.367Z"
   },
   {
    "duration": 79,
    "start_time": "2022-06-10T00:28:37.705Z"
   },
   {
    "duration": 5233,
    "start_time": "2022-06-10T00:28:52.094Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T00:29:29.686Z"
   },
   {
    "duration": 313,
    "start_time": "2022-06-10T00:29:30.023Z"
   },
   {
    "duration": 29,
    "start_time": "2022-06-10T00:29:33.963Z"
   },
   {
    "duration": 449,
    "start_time": "2022-06-10T00:29:34.285Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T00:29:38.089Z"
   },
   {
    "duration": 75,
    "start_time": "2022-06-10T00:29:38.456Z"
   },
   {
    "duration": 5184,
    "start_time": "2022-06-10T00:29:54.449Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T00:30:21.602Z"
   },
   {
    "duration": 171,
    "start_time": "2022-06-10T00:30:21.957Z"
   },
   {
    "duration": 178,
    "start_time": "2022-06-10T00:30:51.050Z"
   },
   {
    "duration": 20511,
    "start_time": "2022-06-10T00:31:04.318Z"
   },
   {
    "duration": 5137,
    "start_time": "2022-06-10T00:31:35.294Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T00:32:22.186Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T00:32:42.154Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T00:33:01.663Z"
   },
   {
    "duration": 220,
    "start_time": "2022-06-10T00:33:02.612Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T00:33:30.615Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-10T00:34:17.312Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-10T00:36:57.996Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T00:37:13.174Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T00:37:14.120Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T00:37:24.978Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T00:37:29.804Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T00:37:35.063Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-10T00:37:41.065Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T00:37:41.613Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-10T00:38:23.440Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-10T00:38:26.993Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-10T00:38:32.632Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T00:38:36.806Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T00:39:40.637Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T00:39:46.977Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T00:39:59.513Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T00:40:06.885Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T00:40:11.238Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-10T00:43:08.364Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T00:44:37.860Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T00:44:55.133Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T00:45:08.121Z"
   },
   {
    "duration": 925,
    "start_time": "2022-06-10T00:45:58.151Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-10T00:45:59.078Z"
   },
   {
    "duration": 23,
    "start_time": "2022-06-10T00:45:59.120Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T00:45:59.144Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T00:45:59.158Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T00:45:59.163Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-10T00:45:59.175Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-10T00:45:59.180Z"
   },
   {
    "duration": 37,
    "start_time": "2022-06-10T00:45:59.199Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-10T00:45:59.238Z"
   },
   {
    "duration": 109,
    "start_time": "2022-06-10T00:45:59.247Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:45:59.358Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T00:46:23.539Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T00:46:25.137Z"
   },
   {
    "duration": 1005,
    "start_time": "2022-06-10T00:46:59.541Z"
   },
   {
    "duration": 45,
    "start_time": "2022-06-10T00:47:00.548Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T00:47:00.594Z"
   },
   {
    "duration": 32,
    "start_time": "2022-06-10T00:47:00.617Z"
   },
   {
    "duration": 37,
    "start_time": "2022-06-10T00:47:00.651Z"
   },
   {
    "duration": 34,
    "start_time": "2022-06-10T00:47:00.689Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T00:47:00.725Z"
   },
   {
    "duration": 43,
    "start_time": "2022-06-10T00:47:00.743Z"
   },
   {
    "duration": 38,
    "start_time": "2022-06-10T00:47:00.788Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-10T00:47:00.828Z"
   },
   {
    "duration": 55,
    "start_time": "2022-06-10T00:47:00.847Z"
   },
   {
    "duration": 28,
    "start_time": "2022-06-10T00:47:00.904Z"
   },
   {
    "duration": 32,
    "start_time": "2022-06-10T00:47:44.834Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T00:47:45.887Z"
   },
   {
    "duration": 24,
    "start_time": "2022-06-10T00:47:51.650Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T00:47:52.033Z"
   },
   {
    "duration": 1015,
    "start_time": "2022-06-10T00:49:06.691Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-10T00:49:07.707Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-10T00:49:07.751Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-10T00:49:07.774Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T00:49:07.793Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T00:49:07.799Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T00:49:07.814Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T00:49:07.828Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-10T00:49:07.843Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-10T00:49:07.861Z"
   },
   {
    "duration": 30,
    "start_time": "2022-06-10T00:49:07.871Z"
   },
   {
    "duration": 31,
    "start_time": "2022-06-10T00:49:07.903Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T00:49:07.936Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T00:49:07.952Z"
   },
   {
    "duration": 983,
    "start_time": "2022-06-10T00:50:43.103Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-10T00:50:44.088Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T00:50:44.131Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T00:50:44.154Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T00:50:44.167Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T00:50:44.172Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-10T00:50:44.185Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T00:50:44.190Z"
   },
   {
    "duration": 38,
    "start_time": "2022-06-10T00:50:44.203Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T00:50:44.243Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T00:50:44.253Z"
   },
   {
    "duration": 110,
    "start_time": "2022-06-10T00:50:44.266Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.378Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.379Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.380Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.381Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.382Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.382Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.383Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.384Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.385Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.386Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.387Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.388Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.388Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.389Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.390Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.391Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.392Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.392Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.393Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.394Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.395Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.396Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.427Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T00:50:44.428Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T00:51:27.360Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T00:52:19.678Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T00:52:26.829Z"
   },
   {
    "duration": 1001,
    "start_time": "2022-06-10T00:52:39.645Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-10T00:52:40.648Z"
   },
   {
    "duration": 23,
    "start_time": "2022-06-10T00:52:40.691Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T00:52:40.715Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T00:52:40.729Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T00:52:40.734Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-10T00:52:40.747Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T00:52:40.751Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T00:52:40.768Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T00:52:40.785Z"
   },
   {
    "duration": 51,
    "start_time": "2022-06-10T00:52:40.795Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T00:52:44.064Z"
   },
   {
    "duration": 1031,
    "start_time": "2022-06-10T00:53:25.949Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-10T00:53:26.982Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-10T00:53:27.025Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T00:53:27.048Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T00:53:27.061Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T00:53:27.066Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T00:53:27.081Z"
   },
   {
    "duration": 23,
    "start_time": "2022-06-10T00:53:27.086Z"
   },
   {
    "duration": 31,
    "start_time": "2022-06-10T00:53:27.111Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-10T00:53:27.144Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T00:53:39.110Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-10T00:54:05.436Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-10T00:54:23.858Z"
   },
   {
    "duration": 30,
    "start_time": "2022-06-10T00:54:30.731Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T00:54:34.953Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T00:54:39.871Z"
   },
   {
    "duration": 1073,
    "start_time": "2022-06-10T01:00:09.036Z"
   },
   {
    "duration": 43,
    "start_time": "2022-06-10T01:00:10.111Z"
   },
   {
    "duration": 149,
    "start_time": "2022-06-10T01:00:10.155Z"
   },
   {
    "duration": 33,
    "start_time": "2022-06-10T01:00:10.306Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-10T01:00:10.341Z"
   },
   {
    "duration": 31,
    "start_time": "2022-06-10T01:00:10.352Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T01:00:10.385Z"
   },
   {
    "duration": 27,
    "start_time": "2022-06-10T01:00:10.391Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-10T01:00:10.420Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T01:00:10.442Z"
   },
   {
    "duration": 26,
    "start_time": "2022-06-10T01:00:10.453Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-10T01:00:33.369Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T01:00:34.294Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T01:00:37.616Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-10T01:00:38.058Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-10T01:00:43.275Z"
   },
   {
    "duration": 1052,
    "start_time": "2022-06-10T01:02:27.928Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-10T01:02:28.981Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T01:02:29.025Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T01:02:29.049Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:02:29.062Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-10T01:02:29.068Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:02:29.087Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T01:02:29.092Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-10T01:02:29.126Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T01:02:29.145Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T01:02:29.155Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-10T01:02:29.171Z"
   },
   {
    "duration": 34,
    "start_time": "2022-06-10T01:02:29.194Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-10T01:02:29.230Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T01:02:29.239Z"
   },
   {
    "duration": 1049,
    "start_time": "2022-06-10T01:03:18.851Z"
   },
   {
    "duration": 43,
    "start_time": "2022-06-10T01:03:19.901Z"
   },
   {
    "duration": 23,
    "start_time": "2022-06-10T01:03:19.945Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T01:03:19.970Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T01:03:19.982Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-10T01:03:19.988Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-10T01:03:20.011Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-10T01:03:20.031Z"
   },
   {
    "duration": 24,
    "start_time": "2022-06-10T01:03:20.049Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T01:03:20.076Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T01:03:20.093Z"
   },
   {
    "duration": 43,
    "start_time": "2022-06-10T01:03:20.110Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T01:03:20.154Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T01:03:20.170Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T01:03:20.181Z"
   },
   {
    "duration": 36,
    "start_time": "2022-06-10T01:03:20.196Z"
   },
   {
    "duration": 1031,
    "start_time": "2022-06-10T01:03:57.651Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-10T01:03:58.684Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T01:03:58.728Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T01:03:58.752Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T01:03:58.766Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T01:03:58.772Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:03:58.786Z"
   },
   {
    "duration": 36,
    "start_time": "2022-06-10T01:03:58.791Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-10T01:03:58.829Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T01:03:58.847Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-10T01:03:58.857Z"
   },
   {
    "duration": 30,
    "start_time": "2022-06-10T01:03:58.876Z"
   },
   {
    "duration": 34,
    "start_time": "2022-06-10T01:03:58.907Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-10T01:03:58.943Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-10T01:03:58.952Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-10T01:03:58.964Z"
   },
   {
    "duration": 943,
    "start_time": "2022-06-10T01:04:27.380Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-10T01:04:28.326Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T01:04:28.369Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T01:04:28.392Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T01:04:28.406Z"
   },
   {
    "duration": 29,
    "start_time": "2022-06-10T01:04:28.412Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:04:28.443Z"
   },
   {
    "duration": 26,
    "start_time": "2022-06-10T01:04:28.448Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-10T01:04:28.476Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T01:04:28.497Z"
   },
   {
    "duration": 26,
    "start_time": "2022-06-10T01:04:28.511Z"
   },
   {
    "duration": 107,
    "start_time": "2022-06-10T01:04:28.539Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T01:04:28.648Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T01:04:28.649Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T01:04:28.650Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T01:04:28.651Z"
   },
   {
    "duration": 26,
    "start_time": "2022-06-10T01:04:57.807Z"
   },
   {
    "duration": 1001,
    "start_time": "2022-06-10T01:05:36.690Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-10T01:05:37.693Z"
   },
   {
    "duration": 23,
    "start_time": "2022-06-10T01:05:37.737Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T01:05:37.761Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T01:05:37.774Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T01:05:37.780Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-10T01:05:37.794Z"
   },
   {
    "duration": 38,
    "start_time": "2022-06-10T01:05:37.799Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-10T01:05:37.839Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-10T01:05:37.860Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-10T01:05:37.878Z"
   },
   {
    "duration": 43,
    "start_time": "2022-06-10T01:05:37.898Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-10T01:05:37.943Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-10T01:05:37.962Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T01:05:37.972Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T01:05:37.987Z"
   },
   {
    "duration": 25,
    "start_time": "2022-06-10T01:06:18.372Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-10T01:06:27.833Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:06:42.748Z"
   },
   {
    "duration": 29,
    "start_time": "2022-06-10T01:06:55.211Z"
   },
   {
    "duration": 63,
    "start_time": "2022-06-10T01:06:56.369Z"
   },
   {
    "duration": 2727,
    "start_time": "2022-06-10T01:07:05.360Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:07:13.304Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-10T01:07:15.255Z"
   },
   {
    "duration": 104,
    "start_time": "2022-06-10T01:07:15.984Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-10T01:07:22.475Z"
   },
   {
    "duration": 3856,
    "start_time": "2022-06-10T01:07:26.308Z"
   },
   {
    "duration": 24,
    "start_time": "2022-06-10T01:07:39.405Z"
   },
   {
    "duration": 56,
    "start_time": "2022-06-10T01:07:43.472Z"
   },
   {
    "duration": 58,
    "start_time": "2022-06-10T01:08:15.939Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T01:09:09.658Z"
   },
   {
    "duration": 7577,
    "start_time": "2022-06-10T01:09:14.978Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T01:11:00.965Z"
   },
   {
    "duration": 1079,
    "start_time": "2022-06-10T01:11:47.223Z"
   },
   {
    "duration": 44,
    "start_time": "2022-06-10T01:11:48.304Z"
   },
   {
    "duration": 25,
    "start_time": "2022-06-10T01:11:48.350Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T01:11:48.377Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T01:11:48.392Z"
   },
   {
    "duration": 28,
    "start_time": "2022-06-10T01:11:48.399Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:11:48.429Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-10T01:11:48.434Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-10T01:11:48.452Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T01:11:48.473Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T01:11:48.484Z"
   },
   {
    "duration": 49,
    "start_time": "2022-06-10T01:11:48.502Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T01:11:48.552Z"
   },
   {
    "duration": 113,
    "start_time": "2022-06-10T01:11:48.630Z"
   },
   {
    "duration": 88,
    "start_time": "2022-06-10T01:11:48.745Z"
   },
   {
    "duration": 113,
    "start_time": "2022-06-10T01:11:48.835Z"
   },
   {
    "duration": 82,
    "start_time": "2022-06-10T01:11:48.949Z"
   },
   {
    "duration": 2895,
    "start_time": "2022-06-10T01:11:49.033Z"
   },
   {
    "duration": 97,
    "start_time": "2022-06-10T01:11:51.932Z"
   },
   {
    "duration": 103,
    "start_time": "2022-06-10T01:11:52.031Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T01:11:52.136Z"
   },
   {
    "duration": 3923,
    "start_time": "2022-06-10T01:11:52.229Z"
   },
   {
    "duration": 118,
    "start_time": "2022-06-10T01:11:56.226Z"
   },
   {
    "duration": 1075,
    "start_time": "2022-06-10T01:12:48.805Z"
   },
   {
    "duration": 43,
    "start_time": "2022-06-10T01:12:49.882Z"
   },
   {
    "duration": 23,
    "start_time": "2022-06-10T01:12:49.926Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T01:12:49.950Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-10T01:12:49.964Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T01:12:49.972Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-10T01:12:49.986Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T01:12:49.997Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T01:12:50.026Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-10T01:12:50.044Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-10T01:12:50.054Z"
   },
   {
    "duration": 34,
    "start_time": "2022-06-10T01:12:50.074Z"
   },
   {
    "duration": 117,
    "start_time": "2022-06-10T01:12:50.110Z"
   },
   {
    "duration": 111,
    "start_time": "2022-06-10T01:12:50.232Z"
   },
   {
    "duration": 84,
    "start_time": "2022-06-10T01:12:50.345Z"
   },
   {
    "duration": 109,
    "start_time": "2022-06-10T01:12:50.432Z"
   },
   {
    "duration": 87,
    "start_time": "2022-06-10T01:12:50.543Z"
   },
   {
    "duration": 2797,
    "start_time": "2022-06-10T01:12:50.633Z"
   },
   {
    "duration": 97,
    "start_time": "2022-06-10T01:12:53.432Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T01:12:53.530Z"
   },
   {
    "duration": 92,
    "start_time": "2022-06-10T01:12:53.544Z"
   },
   {
    "duration": 3932,
    "start_time": "2022-06-10T01:12:53.727Z"
   },
   {
    "duration": 182,
    "start_time": "2022-06-10T01:12:57.662Z"
   },
   {
    "duration": 25,
    "start_time": "2022-06-10T01:14:33.379Z"
   },
   {
    "duration": 103,
    "start_time": "2022-06-10T01:14:47.279Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-10T01:14:59.272Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T01:15:06.478Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-10T01:15:13.564Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T01:15:34.727Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-10T01:15:57.237Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:16:23.840Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:16:30.644Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:16:39.910Z"
   },
   {
    "duration": 1018,
    "start_time": "2022-06-10T01:17:30.163Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-10T01:17:31.183Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T01:17:31.225Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-10T01:17:31.248Z"
   },
   {
    "duration": 28,
    "start_time": "2022-06-10T01:17:31.292Z"
   },
   {
    "duration": 31,
    "start_time": "2022-06-10T01:17:31.322Z"
   },
   {
    "duration": 40,
    "start_time": "2022-06-10T01:17:31.355Z"
   },
   {
    "duration": 33,
    "start_time": "2022-06-10T01:17:31.396Z"
   },
   {
    "duration": 32,
    "start_time": "2022-06-10T01:17:31.431Z"
   },
   {
    "duration": 37,
    "start_time": "2022-06-10T01:17:31.465Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-10T01:17:31.503Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-10T01:17:31.546Z"
   },
   {
    "duration": 50,
    "start_time": "2022-06-10T01:17:31.589Z"
   },
   {
    "duration": 119,
    "start_time": "2022-06-10T01:17:31.726Z"
   },
   {
    "duration": 83,
    "start_time": "2022-06-10T01:17:31.847Z"
   },
   {
    "duration": 115,
    "start_time": "2022-06-10T01:17:31.935Z"
   },
   {
    "duration": 78,
    "start_time": "2022-06-10T01:17:32.052Z"
   },
   {
    "duration": 2841,
    "start_time": "2022-06-10T01:17:32.135Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-10T01:17:35.029Z"
   },
   {
    "duration": 104,
    "start_time": "2022-06-10T01:17:35.037Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T01:17:35.142Z"
   },
   {
    "duration": 3997,
    "start_time": "2022-06-10T01:17:35.159Z"
   },
   {
    "duration": 276,
    "start_time": "2022-06-10T01:17:39.158Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T01:17:39.435Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T01:17:39.437Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:17:53.718Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-10T01:17:59.060Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:18:14.346Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T01:19:29.114Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:19:34.544Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:19:53.640Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:20:00.647Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-10T01:20:34.425Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:20:40.637Z"
   },
   {
    "duration": 931,
    "start_time": "2022-06-10T01:21:28.967Z"
   },
   {
    "duration": 43,
    "start_time": "2022-06-10T01:21:29.900Z"
   },
   {
    "duration": 24,
    "start_time": "2022-06-10T01:21:29.944Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T01:21:29.970Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:21:29.984Z"
   },
   {
    "duration": 37,
    "start_time": "2022-06-10T01:21:29.990Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:21:30.029Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T01:21:30.035Z"
   },
   {
    "duration": 46,
    "start_time": "2022-06-10T01:21:30.058Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T01:21:30.106Z"
   },
   {
    "duration": 63,
    "start_time": "2022-06-10T01:21:30.122Z"
   },
   {
    "duration": 46,
    "start_time": "2022-06-10T01:21:30.187Z"
   },
   {
    "duration": 92,
    "start_time": "2022-06-10T01:21:30.234Z"
   },
   {
    "duration": 133,
    "start_time": "2022-06-10T01:21:30.330Z"
   },
   {
    "duration": 170,
    "start_time": "2022-06-10T01:21:30.465Z"
   },
   {
    "duration": 34,
    "start_time": "2022-06-10T01:21:30.637Z"
   },
   {
    "duration": 66,
    "start_time": "2022-06-10T01:21:30.672Z"
   },
   {
    "duration": 2752,
    "start_time": "2022-06-10T01:21:30.740Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-10T01:21:33.529Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T01:21:33.627Z"
   },
   {
    "duration": 26,
    "start_time": "2022-06-10T01:21:33.650Z"
   },
   {
    "duration": 3951,
    "start_time": "2022-06-10T01:21:33.677Z"
   },
   {
    "duration": 311,
    "start_time": "2022-06-10T01:21:37.630Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T01:21:37.942Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T01:21:37.944Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T01:21:37.944Z"
   },
   {
    "duration": 968,
    "start_time": "2022-06-10T01:22:07.514Z"
   },
   {
    "duration": 1006,
    "start_time": "2022-06-10T01:22:45.590Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-10T01:22:46.598Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-10T01:22:46.641Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T01:22:46.663Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:22:46.679Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T01:22:46.685Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-10T01:22:46.699Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T01:22:46.706Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T01:22:46.729Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T01:22:46.746Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-10T01:22:46.756Z"
   },
   {
    "duration": 28,
    "start_time": "2022-06-10T01:22:46.777Z"
   },
   {
    "duration": 44,
    "start_time": "2022-06-10T01:22:46.806Z"
   },
   {
    "duration": 114,
    "start_time": "2022-06-10T01:22:46.930Z"
   },
   {
    "duration": 84,
    "start_time": "2022-06-10T01:22:47.047Z"
   },
   {
    "duration": 112,
    "start_time": "2022-06-10T01:22:47.134Z"
   },
   {
    "duration": 71,
    "start_time": "2022-06-10T01:22:47.259Z"
   },
   {
    "duration": 2850,
    "start_time": "2022-06-10T01:22:47.333Z"
   },
   {
    "duration": 99,
    "start_time": "2022-06-10T01:22:50.228Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T01:22:50.330Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T01:22:50.340Z"
   },
   {
    "duration": 3988,
    "start_time": "2022-06-10T01:22:50.355Z"
   },
   {
    "duration": 1098,
    "start_time": "2022-06-10T01:22:54.347Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:22:55.447Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-10T01:22:55.452Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T01:22:55.460Z"
   },
   {
    "duration": 7207,
    "start_time": "2022-06-10T01:23:27.044Z"
   },
   {
    "duration": 7124,
    "start_time": "2022-06-10T01:24:27.410Z"
   },
   {
    "duration": 855,
    "start_time": "2022-06-10T01:24:41.491Z"
   },
   {
    "duration": 521,
    "start_time": "2022-06-10T01:36:12.553Z"
   },
   {
    "duration": 545,
    "start_time": "2022-06-10T01:36:21.467Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T01:36:42.951Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T01:36:57.177Z"
   },
   {
    "duration": 35,
    "start_time": "2022-06-10T01:37:21.182Z"
   },
   {
    "duration": 99,
    "start_time": "2022-06-10T01:37:25.087Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:39:37.316Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T01:40:00.114Z"
   },
   {
    "duration": 969,
    "start_time": "2022-06-10T01:42:04.280Z"
   },
   {
    "duration": 992,
    "start_time": "2022-06-10T01:42:52.696Z"
   },
   {
    "duration": 50,
    "start_time": "2022-06-10T01:42:53.691Z"
   },
   {
    "duration": 36,
    "start_time": "2022-06-10T01:42:53.744Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-10T01:42:53.783Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T01:42:53.805Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T01:42:53.827Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T01:42:53.840Z"
   },
   {
    "duration": 26,
    "start_time": "2022-06-10T01:42:53.846Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-10T01:42:53.874Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T01:42:53.894Z"
   },
   {
    "duration": 36,
    "start_time": "2022-06-10T01:42:53.905Z"
   },
   {
    "duration": 29,
    "start_time": "2022-06-10T01:42:53.942Z"
   },
   {
    "duration": 57,
    "start_time": "2022-06-10T01:42:53.973Z"
   },
   {
    "duration": 108,
    "start_time": "2022-06-10T01:42:54.034Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T01:42:54.144Z"
   },
   {
    "duration": 108,
    "start_time": "2022-06-10T01:42:54.229Z"
   },
   {
    "duration": 91,
    "start_time": "2022-06-10T01:42:54.339Z"
   },
   {
    "duration": 2653,
    "start_time": "2022-06-10T01:42:54.433Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-10T01:42:57.128Z"
   },
   {
    "duration": 97,
    "start_time": "2022-06-10T01:42:57.137Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-10T01:42:57.235Z"
   },
   {
    "duration": 4019,
    "start_time": "2022-06-10T01:42:57.256Z"
   },
   {
    "duration": 1163,
    "start_time": "2022-06-10T01:43:01.277Z"
   },
   {
    "duration": 7404,
    "start_time": "2022-06-10T01:43:02.441Z"
   },
   {
    "duration": 925,
    "start_time": "2022-06-10T01:43:09.847Z"
   },
   {
    "duration": 52558,
    "start_time": "2022-06-10T01:43:46.963Z"
   },
   {
    "duration": 978,
    "start_time": "2022-06-10T01:48:19.679Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-10T01:48:20.659Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-10T01:48:20.702Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-10T01:48:20.725Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T01:48:20.749Z"
   },
   {
    "duration": 47,
    "start_time": "2022-06-10T01:48:20.761Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-10T01:48:20.810Z"
   },
   {
    "duration": 32,
    "start_time": "2022-06-10T01:48:20.830Z"
   },
   {
    "duration": 26,
    "start_time": "2022-06-10T01:48:20.864Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-10T01:48:20.892Z"
   },
   {
    "duration": 33,
    "start_time": "2022-06-10T01:48:20.912Z"
   },
   {
    "duration": 79,
    "start_time": "2022-06-10T01:48:20.946Z"
   },
   {
    "duration": 24,
    "start_time": "2022-06-10T01:48:21.027Z"
   },
   {
    "duration": 125,
    "start_time": "2022-06-10T01:48:21.129Z"
   },
   {
    "duration": 74,
    "start_time": "2022-06-10T01:48:21.256Z"
   },
   {
    "duration": 109,
    "start_time": "2022-06-10T01:48:21.333Z"
   },
   {
    "duration": 84,
    "start_time": "2022-06-10T01:48:21.444Z"
   },
   {
    "duration": 2896,
    "start_time": "2022-06-10T01:48:21.532Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T01:48:24.431Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-10T01:48:24.528Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T01:48:24.549Z"
   },
   {
    "duration": 3960,
    "start_time": "2022-06-10T01:48:24.626Z"
   },
   {
    "duration": 1042,
    "start_time": "2022-06-10T01:48:28.630Z"
   },
   {
    "duration": 8122,
    "start_time": "2022-06-10T01:48:29.674Z"
   },
   {
    "duration": 872,
    "start_time": "2022-06-10T01:48:37.798Z"
   },
   {
    "duration": 50831,
    "start_time": "2022-06-10T01:48:38.672Z"
   },
   {
    "duration": 418951,
    "start_time": "2022-06-10T01:49:29.505Z"
   },
   {
    "duration": 906,
    "start_time": "2022-06-10T01:56:52.080Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-10T01:56:52.989Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T01:56:53.032Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T01:56:53.056Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T01:56:53.069Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-10T01:56:53.076Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-10T01:56:53.095Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T01:56:53.099Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T01:56:53.126Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T01:56:53.143Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T01:56:53.154Z"
   },
   {
    "duration": 27,
    "start_time": "2022-06-10T01:56:53.170Z"
   },
   {
    "duration": 46,
    "start_time": "2022-06-10T01:56:53.198Z"
   },
   {
    "duration": 186,
    "start_time": "2022-06-10T01:56:53.252Z"
   },
   {
    "duration": 87,
    "start_time": "2022-06-10T01:56:53.441Z"
   },
   {
    "duration": 106,
    "start_time": "2022-06-10T01:56:53.531Z"
   },
   {
    "duration": 37,
    "start_time": "2022-06-10T01:56:53.638Z"
   },
   {
    "duration": 56,
    "start_time": "2022-06-10T01:56:53.676Z"
   },
   {
    "duration": 105,
    "start_time": "2022-06-10T01:56:53.734Z"
   },
   {
    "duration": 90,
    "start_time": "2022-06-10T01:56:53.840Z"
   },
   {
    "duration": 1081,
    "start_time": "2022-06-10T01:56:53.932Z"
   },
   {
    "duration": 1651,
    "start_time": "2022-06-10T01:56:55.015Z"
   },
   {
    "duration": 351,
    "start_time": "2022-06-10T01:56:56.668Z"
   },
   {
    "duration": 50596,
    "start_time": "2022-06-10T01:56:57.021Z"
   },
   {
    "duration": 92142,
    "start_time": "2022-06-10T01:57:47.618Z"
   },
   {
    "duration": 23636,
    "start_time": "2022-06-10T01:59:19.761Z"
   },
   {
    "duration": 29,
    "start_time": "2022-06-10T01:59:43.399Z"
   },
   {
    "duration": 198,
    "start_time": "2022-06-10T01:59:43.431Z"
   },
   {
    "duration": 24,
    "start_time": "2022-06-10T01:59:43.630Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T01:59:43.655Z"
   },
   {
    "duration": 62,
    "start_time": "2022-06-10T01:59:43.667Z"
   },
   {
    "duration": 323,
    "start_time": "2022-06-10T02:08:52.400Z"
   },
   {
    "duration": 995,
    "start_time": "2022-06-10T02:10:07.181Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-10T02:10:08.178Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T02:10:08.221Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-10T02:10:08.245Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T02:10:08.266Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T02:10:08.271Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-10T02:10:08.284Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T02:10:08.289Z"
   },
   {
    "duration": 38,
    "start_time": "2022-06-10T02:10:08.302Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T02:10:08.341Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T02:10:08.352Z"
   },
   {
    "duration": 27,
    "start_time": "2022-06-10T02:10:08.367Z"
   },
   {
    "duration": 49,
    "start_time": "2022-06-10T02:10:08.395Z"
   },
   {
    "duration": 187,
    "start_time": "2022-06-10T02:10:08.447Z"
   },
   {
    "duration": 91,
    "start_time": "2022-06-10T02:10:08.637Z"
   },
   {
    "duration": 108,
    "start_time": "2022-06-10T02:10:08.730Z"
   },
   {
    "duration": 39,
    "start_time": "2022-06-10T02:10:08.839Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-10T02:10:08.928Z"
   },
   {
    "duration": 102,
    "start_time": "2022-06-10T02:10:08.936Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T02:10:09.040Z"
   },
   {
    "duration": 1158,
    "start_time": "2022-06-10T02:10:09.054Z"
   },
   {
    "duration": 1604,
    "start_time": "2022-06-10T02:10:10.214Z"
   },
   {
    "duration": 362,
    "start_time": "2022-06-10T02:10:11.820Z"
   },
   {
    "duration": 50507,
    "start_time": "2022-06-10T02:10:12.184Z"
   },
   {
    "duration": 91880,
    "start_time": "2022-06-10T02:11:02.693Z"
   },
   {
    "duration": 22970,
    "start_time": "2022-06-10T02:12:34.575Z"
   },
   {
    "duration": 241,
    "start_time": "2022-06-10T02:12:57.547Z"
   },
   {
    "duration": 43,
    "start_time": "2022-06-10T02:12:57.789Z"
   },
   {
    "duration": 112,
    "start_time": "2022-06-10T02:12:57.838Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T02:12:57.951Z"
   },
   {
    "duration": 62,
    "start_time": "2022-06-10T02:12:57.966Z"
   },
   {
    "duration": 172,
    "start_time": "2022-06-10T02:17:39.755Z"
   },
   {
    "duration": 203,
    "start_time": "2022-06-10T02:17:54.624Z"
   },
   {
    "duration": 132,
    "start_time": "2022-06-10T02:17:57.817Z"
   },
   {
    "duration": 26,
    "start_time": "2022-06-10T02:20:00.724Z"
   },
   {
    "duration": 1014,
    "start_time": "2022-06-10T02:21:08.768Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-10T02:21:09.784Z"
   },
   {
    "duration": 23,
    "start_time": "2022-06-10T02:21:09.827Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T02:21:09.852Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T02:21:09.867Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T02:21:09.872Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-10T02:21:09.887Z"
   },
   {
    "duration": 40,
    "start_time": "2022-06-10T02:21:09.892Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-10T02:21:09.933Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T02:21:09.950Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T02:21:09.961Z"
   },
   {
    "duration": 51,
    "start_time": "2022-06-10T02:21:09.977Z"
   },
   {
    "duration": 100,
    "start_time": "2022-06-10T02:21:10.029Z"
   },
   {
    "duration": 108,
    "start_time": "2022-06-10T02:21:10.133Z"
   },
   {
    "duration": 89,
    "start_time": "2022-06-10T02:21:10.243Z"
   },
   {
    "duration": 108,
    "start_time": "2022-06-10T02:21:10.334Z"
   },
   {
    "duration": 40,
    "start_time": "2022-06-10T02:21:10.443Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-10T02:21:10.529Z"
   },
   {
    "duration": 103,
    "start_time": "2022-06-10T02:21:10.537Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T02:21:10.642Z"
   },
   {
    "duration": 1089,
    "start_time": "2022-06-10T02:21:10.727Z"
   },
   {
    "duration": 1606,
    "start_time": "2022-06-10T02:21:11.817Z"
   },
   {
    "duration": 356,
    "start_time": "2022-06-10T02:21:13.425Z"
   },
   {
    "duration": 50747,
    "start_time": "2022-06-10T02:21:13.783Z"
   },
   {
    "duration": 92605,
    "start_time": "2022-06-10T02:22:04.532Z"
   },
   {
    "duration": 23101,
    "start_time": "2022-06-10T02:23:37.139Z"
   },
   {
    "duration": 246,
    "start_time": "2022-06-10T02:24:00.242Z"
   },
   {
    "duration": 44,
    "start_time": "2022-06-10T02:24:00.490Z"
   },
   {
    "duration": 151,
    "start_time": "2022-06-10T02:24:00.536Z"
   },
   {
    "duration": 102,
    "start_time": "2022-06-10T02:24:00.731Z"
   },
   {
    "duration": 944,
    "start_time": "2022-06-10T02:42:17.331Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-10T02:42:18.276Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-10T02:42:18.319Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T02:42:18.343Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T02:42:18.358Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T02:42:18.364Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T02:42:18.376Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T02:42:18.381Z"
   },
   {
    "duration": 43,
    "start_time": "2022-06-10T02:42:18.396Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T02:42:18.441Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-10T02:42:18.451Z"
   },
   {
    "duration": 30,
    "start_time": "2022-06-10T02:42:18.472Z"
   },
   {
    "duration": 43,
    "start_time": "2022-06-10T02:42:18.503Z"
   },
   {
    "duration": 198,
    "start_time": "2022-06-10T02:42:18.630Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-10T02:42:18.830Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T02:42:18.928Z"
   },
   {
    "duration": 87,
    "start_time": "2022-06-10T02:42:18.945Z"
   },
   {
    "duration": 97,
    "start_time": "2022-06-10T02:42:19.034Z"
   },
   {
    "duration": 100,
    "start_time": "2022-06-10T02:42:19.133Z"
   },
   {
    "duration": 97,
    "start_time": "2022-06-10T02:42:19.234Z"
   },
   {
    "duration": 1084,
    "start_time": "2022-06-10T02:42:19.334Z"
   },
   {
    "duration": 1609,
    "start_time": "2022-06-10T02:42:20.419Z"
   },
   {
    "duration": 365,
    "start_time": "2022-06-10T02:42:22.030Z"
   },
   {
    "duration": 51033,
    "start_time": "2022-06-10T02:42:22.397Z"
   },
   {
    "duration": 91881,
    "start_time": "2022-06-10T02:43:13.432Z"
   },
   {
    "duration": 23380,
    "start_time": "2022-06-10T02:44:45.315Z"
   },
   {
    "duration": 255,
    "start_time": "2022-06-10T02:45:08.696Z"
   },
   {
    "duration": 427,
    "start_time": "2022-06-10T02:45:08.954Z"
   },
   {
    "duration": 1152,
    "start_time": "2022-06-10T21:25:45.286Z"
   },
   {
    "duration": 167,
    "start_time": "2022-06-10T21:25:52.017Z"
   },
   {
    "duration": 44,
    "start_time": "2022-06-10T21:25:59.754Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-10T21:26:00.265Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T21:27:50.660Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T21:28:03.251Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T21:29:45.910Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-10T21:30:53.097Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T21:30:53.902Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-10T21:30:58.571Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-10T21:38:29.723Z"
   },
   {
    "duration": 30,
    "start_time": "2022-06-10T21:41:08.126Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T21:41:28.036Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T21:41:45.931Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T21:41:57.392Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-10T21:42:10.019Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T21:42:21.134Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-10T21:51:48.477Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T21:51:58.502Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T21:52:17.597Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T21:52:41.032Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T21:52:46.521Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T21:53:15.811Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-10T21:53:39.897Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T21:54:47.545Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-10T21:56:06.431Z"
   },
   {
    "duration": 55,
    "start_time": "2022-06-10T22:01:09.639Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T22:02:08.022Z"
   },
   {
    "duration": 37,
    "start_time": "2022-06-10T22:02:10.635Z"
   },
   {
    "duration": 115,
    "start_time": "2022-06-10T22:03:47.657Z"
   },
   {
    "duration": 75,
    "start_time": "2022-06-10T22:05:36.989Z"
   },
   {
    "duration": 98,
    "start_time": "2022-06-10T22:05:57.577Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T22:12:14.881Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T22:14:32.323Z"
   },
   {
    "duration": 77,
    "start_time": "2022-06-10T22:25:23.888Z"
   },
   {
    "duration": 132,
    "start_time": "2022-06-10T22:31:37.274Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T22:31:40.996Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T22:31:41.787Z"
   },
   {
    "duration": 23,
    "start_time": "2022-06-10T22:31:42.645Z"
   },
   {
    "duration": 1230,
    "start_time": "2022-06-10T22:35:25.343Z"
   },
   {
    "duration": 1952,
    "start_time": "2022-06-10T22:36:36.358Z"
   },
   {
    "duration": 414,
    "start_time": "2022-06-10T22:37:54.200Z"
   },
   {
    "duration": 62033,
    "start_time": "2022-06-10T22:38:55.515Z"
   },
   {
    "duration": 112117,
    "start_time": "2022-06-10T22:42:28.048Z"
   },
   {
    "duration": 28683,
    "start_time": "2022-06-10T22:45:36.096Z"
   },
   {
    "duration": 291,
    "start_time": "2022-06-10T22:47:56.299Z"
   },
   {
    "duration": 300,
    "start_time": "2022-06-10T22:52:02.870Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-10T22:52:34.060Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-10T22:52:48.017Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T22:53:37.327Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-10T22:54:53.949Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
